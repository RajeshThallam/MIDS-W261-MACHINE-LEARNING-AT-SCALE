{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkgreen\">DATSCIW261 ASSIGNMENT 13</span>\n",
    "#### MIDS UC Berkeley, Machine Learning at Scale\n",
    "\n",
    "<b>AUTHORS</b> : Rajesh Thallam <br>\n",
    "<b>EMAIL</b>  : rajesh.thallam@ischool.berkeley.edu <br>\n",
    "<b>WEEK</b>   : 13 <br>\n",
    "<b>DATE</b>   : 09-Dec-15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:dodgerblue;font:12px\">HW13.1</span></h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:firebrick; font-size: 120%;\"><b>Spark implementation of basic PageRank</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue\">\n",
    "Write a basic Spark implementation of the iterative PageRank algorithm that takes sparse adjacency lists as input. Make sure that your implementation utilizes teleportation (1-damping/the number of nodes in the network), and further, distributes the mass of dangling nodes with each iteration so that the output of each iteration is correctly normalized (sums to 1). <br><br>\n",
    "[NOTE: The PageRank algorithm assumes that a random surfer (walker), starting from a random web page, chooses the next page to which it will move by clicking at random, with probability d, one of the hyperlinks in the current page. This probability is represented by a so-called ‘damping factor’ d, where d ∈ (0, 1). Otherwise, with probability (1 − d), the surfer jumps to any web page in the network. If a page is a dangling end, meaning it has no outgoing hyperlinks, the random surfer selects an arbitrary web page from a uniform distribution and “teleports” to that page] <br><br>\n",
    "In your Spark solution, please use broadcast variables and caching to make sure your code is as efficient as possible. <br><br>\n",
    "As you build your code, use the following [test data to](s3://ucb-mids-mls-networks/PageRank-test.txt) check you implementation: <br><br>\n",
    "Set the teleportation parameter  to 0.15 (1-d, where d, the damping factor is set to 0.85), and crosscheck your work with the true result, displayed in the first image in the Wikipedia articlehttps [PageRank](//en.wikipedia.org/wiki/PageRank) and here for reference are the corresponding resulting PageRank probabilities: <br><br>\n",
    "A,0.033<br>\n",
    "B,0.384<br>\n",
    "C,0.343<br>\n",
    "D,0.039<br>\n",
    "E,0.081<br>\n",
    "F,0.039<br>\n",
    "G,0.016<br>\n",
    "H,0.016<br>\n",
    "I,0.016<br>\n",
    "J,0.016<br>\n",
    "K,0.016<br><br>\n",
    "Run this experiment locally first. Report the local configuration that you used and how long in minutes and seconds it takes to complete your job. <br><br>\n",
    "Repeat this experiment on AWS. Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete your job. (in your notebook, cat the cluster config file)\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:cornflowerblue; font-size: 120%;\"><b>Algorithm</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Stage 1\n",
    "Function Map(Pi, Value)\n",
    "    #Value contains the url of a page and one of its outlinks:[Pi Pik]\n",
    "1: output(Pi; Pik)\n",
    "2: output(Pik; \"\")\n",
    "\n",
    "Function Reduce(Text Key, Text Values[]\n",
    "   #For Key = Pi, Values contains list of outlinks of P[Pi0 Pi1 Pi2 ...]\n",
    "3: Outlinks <- Ranki(Initial Rank)\n",
    "4: for each element Value in Values\n",
    "5:   Outlinks += Value // add Value to Outlinks String\n",
    "6: end for\n",
    "7: output(Pi, Outlinks)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Function Stage-1-Map(Text Pi, Text Value)\n",
    "    #Value contains the rank of page Pi and its outlinks: [Ri Pi0 Pi1 Pi2 ...]\n",
    "1:  if page Pi has outlinks then\n",
    "2:      for each outlink Pk in Value\n",
    "3:          Ni = Number of outlinks\n",
    "4:          output(Pk, (Ri + r + (1-a)/N)/Ni)\n",
    "5:      end for\n",
    "6:      output(Pi, \"m\" Pi0 Pi1 Pi2 ...)(m indicates that the value is the list of outlinks)\n",
    "7:   else if page Pi doesn't have outlinks then\n",
    "8:      output(-1, Ri + r + (1-a)/N)\n",
    "9:      output(Pi, \"m\")\n",
    "10:  end if\n",
    "\n",
    "Function\n",
    "   Stage-1-Reduce(Text Key, Text Values[])\n",
    "     #For Key = -1, Values contains Rank contributions of pages without outlinks -> [Rn0 Rn1 Rn2 ...]\n",
    "     #For Key = P, k, Values contains list of outlinks of Pk and rank contributions to Pk from other pages -> [[m Pi0 Pi1 Pi2 ...] R0/N0 R1/N1 R2/N2...]\n",
    "11:\n",
    "12:   if Key = -1 then\n",
    "13:       r <- 0\n",
    "14:       for each element Rni in Values\n",
    "15:           r += Rni\n",
    "16:       end for\n",
    "17:       r = a * r/N  //N is the number of total pages\n",
    "18:       Write r into a HDFS file\n",
    "19:   else\n",
    "20:       rk <- 0\n",
    "21:       for each element Value in Values\n",
    "22:           if Value is the list of outlinks then\n",
    "23:               Outlinks <- Value delete m\n",
    "24:           else\n",
    "25:               rk += Ri/Ni\n",
    "26:           end if\n",
    "27:       end for\n",
    "28:       rk = a * rk\n",
    "29:       output(Pk, rk Outlinks)\n",
    "30:   end if\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.5.2\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.6 (default, Jun 22 2015 17:58:13)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys #current as of 9/26/2015\n",
    "spark_home = os.environ['SPARK_HOME'] = '/usr/local/spark'\n",
    "\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.8.2.1-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:cornflowerblue; font-size: 120%;\"><b>Pagerank implemetation for toyset</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pagerank_13_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pagerank_13_1.py\n",
    "#!/usr/bin/python\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "from operator import add\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "def pagerank_init(line):\n",
    "    # initialize page rank as 1/N for all nodes with \n",
    "    # outgoing links and emit with graph structure\n",
    "    node, ol = line.split('\\t')\n",
    "    neighbors = '|'.join(ast.literal_eval(ol).keys())\n",
    "    yield node.encode('utf-8'), [1/N, neighbors]\n",
    "\n",
    "def distribute(node, rank_links):\n",
    "    \"\"\"Calculates URL contributions to the rank of other URLs.\"\"\"\n",
    "    r = rank_links[0]\n",
    "    links = rank_links[1]\n",
    "\n",
    "    ol = str(links).split('|')\n",
    "    Ni = len(ol)\n",
    "\n",
    "    # if the node is for dangling (i.e. no outgoing link),\n",
    "    # emit the loss to redistribute to all the incoming\n",
    "    # links to the dangling node\n",
    "    if (Ni == 1 and ol[0] == '') or Ni == 0:\n",
    "        yield 'DANGLING', r\n",
    "    else:\n",
    "        r_new = float(r)/float(Ni)\n",
    "        for l in ol:\n",
    "            yield l, r_new\n",
    "\n",
    "    # recover graph structure\n",
    "    if links <> '':\n",
    "        yield node, links\n",
    "\n",
    "# update pagerank by combining the mass\n",
    "def combine_mass(rank_links):\n",
    "    r = 0.0\n",
    "    out = ''\n",
    "\n",
    "    for i in rank_links.split('~'):\n",
    "        try:\n",
    "            i = ast.literal_eval(i)\n",
    "            if type(i) == float:\n",
    "                r += i\n",
    "            else:\n",
    "                out = i if i else out\n",
    "        except:\n",
    "            out = i if i else out\n",
    "            pass\n",
    "\n",
    "    return str(r) + '~' + str(out)\n",
    "\n",
    "def update_pagerank(node, rank_links, loss, N, a = 0.15):\n",
    "    r = 0.0\n",
    "    out_links = \"\"    \n",
    "        \n",
    "    for i in str(rank_links).split('~'):\n",
    "        try:\n",
    "            i = ast.literal_eval(i)\n",
    "            if type(i) == float:\n",
    "                r = float(i)\n",
    "            else:\n",
    "                out_links = i if i else out_links\n",
    "        except:\n",
    "            out_links = i if i else out_links\n",
    "            pass\n",
    "    \n",
    "    r_new = a * (1/N) + (1-a) * (loss/N + r)\n",
    "    return node, [round(r_new, 5), out_links]\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 4:\n",
    "        print(\"Usage: pagerank <source_file> <iterations> <target_file>\")\n",
    "        exit(-1)\n",
    "\n",
    "    # Initialize the spark context.\n",
    "    sc = SparkContext(appName=\"PythonPageRank\")\n",
    "\n",
    "    lines = sc.textFile(sys.argv[1], 1)\n",
    "    N = 11.0\n",
    "    D = 0.85\n",
    "    a = 0.15\n",
    "\n",
    "    # parse and initialize pagerank\n",
    "    ranks = lines.flatMap(lambda pages: pagerank_init(pages))\n",
    "    \n",
    "    for iteration in range(int(sys.argv[2])):\n",
    "        # contribution from each page\n",
    "        contribs = ranks \\\n",
    "                    .flatMap(lambda (node, rank_links): distribute(node, rank_links)) \\\n",
    "                    .reduceByKey(lambda prev, curr: combine_mass(str(prev) + '~' + str(curr))).cache()\n",
    "        \n",
    "        # find dangling mass\n",
    "        dangling_nodes = contribs.lookup('DANGLING')\n",
    "        dangling_mass = 0.0 if len(dangling_nodes) == 0 else float(str(dangling_nodes[0]).strip('~'))\n",
    "\n",
    "        # update page rank\n",
    "        ranks_new = contribs \\\n",
    "                    .filter(lambda (k, v): k != 'DANGLING') \\\n",
    "                    .map(lambda (node, rank_links): update_pagerank(node, rank_links, dangling_mass, N, a))\n",
    "        ranks = ranks_new\n",
    "                \n",
    "    ranks \\\n",
    "        .map(lambda (node, rank_links): (node, round(rank_links[0], 3), rank_links[1])) \\\n",
    "        .saveAsTextFile(sys.argv[3])\n",
    "    \n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:cornflowerblue; font-size: 120%;\"><b>Running on Local</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/12/07 15:17:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "15/12/07 15:17:14 WARN Utils: Your hostname, rtubuntu resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface eth0)\n",
      "15/12/07 15:17:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "15/12/07 15:17:16 WARN MetricsSystem: Using default name DAGScheduler for source because spark.app.id is not set.\n",
      "22.63user 1.86system 0:35.03elapsed 69%CPU (0avgtext+0avgdata 498340maxresident)k\n",
      "0inputs+3104outputs (0major+269468minor)pagefaults 0swaps\n",
      "================================================================================\n",
      "Time taken to find page rank of the network = 35.26 seconds\n",
      "================================================================================\n",
      "Pagerank of the graph is\n",
      "('A', 0.033, '')\n",
      "('B', 0.384, 'C')\n",
      "('C', 0.343, 'B')\n",
      "('D', 0.039, 'A|B')\n",
      "('E', 0.081, 'B|D|F')\n",
      "('F', 0.039, 'B|E')\n",
      "('G', 0.016, 'B|E')\n",
      "('H', 0.016, 'B|E')\n",
      "('I', 0.016, 'B|E')\n",
      "('J', 0.016, 'E')\n",
      "('K', 0.016, 'E')\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "!rm -fR out_hw13_1\n",
    "!time $SPARK_HOME/bin/spark-submit --name \"PythonPageRank\" --master local[4] ./pagerank_13_1.py ./PageRank-test.txt 100 out_hw13_1\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print \"=\"*80\n",
    "print \"Time taken to find page rank of the network = {:.2f} seconds\".format(end_time - start_time)\n",
    "print \"=\"*80\n",
    "\n",
    "print \"Pagerank of the graph is\"\n",
    "!cat out_hw13_1/part-000* | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:cornflowerblue; font-size: 120%;\"><b>Running on AWS</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aws emr create-cluster --name \"rt-hw13\" --release-label emr-4.2.0 --applications Name=Spark --ec2-attributes KeyName=rthallam_sa_east --log-uri s3://ucb-mids-mls-rajeshthallam/hw13/logs --instance-type m3.xlarge  --instance-count 10 --use-default-roles --configurations file://./emr_config_spark_rt.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "PageRank-test_indexed.txt                       0%    0     0.0KB/s   --:-- ETA\r",
      "PageRank-test_indexed.txt                     100%  168     0.2KB/s   00:00    \r\n"
     ]
    }
   ],
   "source": [
    "!scp -i ~/rthallam_sa_east.pem ./PageRank-test_indexed.txt hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com:/home/hadoop/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pagerank_13_1.py                              100% 3062     3.0KB/s   00:00    \n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/_SUCCESS\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00009\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00010\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00000\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00001\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00005\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00006\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00004\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00007\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00011\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00008\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00012\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00013\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00015\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00016\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00014\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00017\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00018\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00019\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00020\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00023\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00021\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00022\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00025\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00024\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00027\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00026\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00028\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00029\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00030\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00032\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00033\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00034\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00035\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00031\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00003\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00002\n",
      "15/12/07 22:49:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "15/12/07 22:49:53 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-32-212.sa-east-1.compute.internal/172.31.32.212:8032\n",
      "15/12/07 22:49:53 INFO yarn.Client: Requesting a new application from cluster with 9 NodeManagers\n",
      "15/12/07 22:49:53 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (11520 MB per container)\n",
      "15/12/07 22:49:53 INFO yarn.Client: Will allocate AM container, with 1408 MB memory including 384 MB overhead\n",
      "15/12/07 22:49:53 INFO yarn.Client: Setting up container launch context for our AM\n",
      "15/12/07 22:49:53 INFO yarn.Client: Setting up the launch environment for our AM container\n",
      "15/12/07 22:49:53 INFO yarn.Client: Preparing resources for our AM container\n",
      "15/12/07 22:49:54 INFO yarn.Client: Uploading resource file:/usr/lib/spark/lib/spark-assembly-1.5.2-hadoop2.6.0-amzn-2.jar -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0023/spark-assembly-1.5.2-hadoop2.6.0-amzn-2.jar\n",
      "15/12/07 22:49:54 INFO metrics.MetricsSaver: MetricsConfigRecord disabledInCluster: false instanceEngineCycleSec: 60 clusterEngineCycleSec: 60 disableClusterEngine: false maxMemoryMb: 3072 maxInstanceCount: 500 lastModified: 1449482533009 \n",
      "15/12/07 22:49:54 INFO metrics.MetricsSaver: Created MetricsSaver j-KBN00RIHUZBE:i-d5952e37:SparkSubmit:31545 period:60 /mnt/var/em/raw/i-d5952e37_20151207_SparkSubmit_31545_raw.bin\n",
      "15/12/07 22:49:56 INFO metrics.MetricsSaver: 1 aggregated HDFSWriteDelay 2651 raw values into 1 aggregated values, total 1\n",
      "15/12/07 22:49:56 INFO yarn.Client: Uploading resource file:/home/hadoop/src/pagerank_13_1.py -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0023/pagerank_13_1.py\n",
      "15/12/07 22:49:56 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0023/pyspark.zip\n",
      "15/12/07 22:49:56 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.8.2.1-src.zip -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0023/py4j-0.8.2.1-src.zip\n",
      "15/12/07 22:49:56 INFO yarn.Client: Uploading resource file:/tmp/spark-da6da678-31a0-4307-bd5d-f4e28422910a/__spark_conf__7206287122981183140.zip -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0023/__spark_conf__7206287122981183140.zip\n",
      "15/12/07 22:49:56 INFO spark.SecurityManager: Changing view acls to: hadoop\n",
      "15/12/07 22:49:56 INFO spark.SecurityManager: Changing modify acls to: hadoop\n",
      "15/12/07 22:49:56 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hadoop); users with modify permissions: Set(hadoop)\n",
      "15/12/07 22:49:56 INFO yarn.Client: Submitting application 23 to ResourceManager\n",
      "15/12/07 22:49:56 INFO impl.YarnClientImpl: Submitted application application_1449482525945_0023\n",
      "15/12/07 22:49:57 INFO yarn.Client: Application report for application_1449482525945_0023 (state: ACCEPTED)\n",
      "15/12/07 22:49:57 INFO yarn.Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: N/A\n",
      "\t ApplicationMaster host: N/A\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: default\n",
      "\t start time: 1449528596441\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://ip-172-31-32-212.sa-east-1.compute.internal:20888/proxy/application_1449482525945_0023/\n",
      "\t user: hadoop\n",
      "15/12/07 22:49:58 INFO yarn.Client: Application report for application_1449482525945_0023 (state: ACCEPTED)\n",
      "15/12/07 22:49:59 INFO yarn.Client: Application report for application_1449482525945_0023 (state: ACCEPTED)\n",
      "15/12/07 22:50:00 INFO yarn.Client: Application report for application_1449482525945_0023 (state: ACCEPTED)\n",
      "15/12/07 22:50:01 INFO yarn.Client: Application report for application_1449482525945_0023 (state: ACCEPTED)\n",
      "15/12/07 22:50:02 INFO yarn.Client: Application report for application_1449482525945_0023 (state: ACCEPTED)\n",
      "15/12/07 22:50:03 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:03 INFO yarn.Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: N/A\n",
      "\t ApplicationMaster host: 172.31.42.129\n",
      "\t ApplicationMaster RPC port: 0\n",
      "\t queue: default\n",
      "\t start time: 1449528596441\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://ip-172-31-32-212.sa-east-1.compute.internal:20888/proxy/application_1449482525945_0023/\n",
      "\t user: hadoop\n",
      "15/12/07 22:50:04 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:05 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:06 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:07 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:08 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:09 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:10 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:11 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:12 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:13 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:14 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:15 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:16 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:17 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:18 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:19 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:20 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:21 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:22 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:23 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:24 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:25 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:26 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:27 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:28 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:29 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:30 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:31 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:32 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:33 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:34 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:35 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:36 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:37 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:38 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:39 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:40 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:41 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:42 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:43 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:44 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:45 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:46 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:47 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:48 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:49 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:50 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:51 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:52 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:53 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:54 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:55 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:56 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:57 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:58 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:50:59 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:00 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:01 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:02 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:03 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:04 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:05 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:06 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:07 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:08 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:09 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:10 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:11 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:12 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:13 INFO yarn.Client: Application report for application_1449482525945_0023 (state: RUNNING)\n",
      "15/12/07 22:51:14 INFO yarn.Client: Application report for application_1449482525945_0023 (state: FINISHED)\n",
      "15/12/07 22:51:14 INFO yarn.Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: N/A\n",
      "\t ApplicationMaster host: 172.31.42.129\n",
      "\t ApplicationMaster RPC port: 0\n",
      "\t queue: default\n",
      "\t start time: 1449528596441\n",
      "\t final status: SUCCEEDED\n",
      "\t tracking URL: http://ip-172-31-32-212.sa-east-1.compute.internal:20888/proxy/application_1449482525945_0023/history/application_1449482525945_0023/1\n",
      "\t user: hadoop\n",
      "15/12/07 22:51:14 INFO util.ShutdownHookManager: Shutdown hook called\n",
      "15/12/07 22:51:14 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-da6da678-31a0-4307-bd5d-f4e28422910a\n",
      "================================================================================\n",
      "Time taken to find page rank of the network = 98.49 seconds\n",
      "================================================================================\n",
      "Pagerank of the graph is\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00001 to out_hw13_1/part-00001\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00007 to out_hw13_1/part-00007\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00000 to out_hw13_1/part-00000\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/_SUCCESS to out_hw13_1/_SUCCESS\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00004 to out_hw13_1/part-00004\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00006 to out_hw13_1/part-00006\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00008 to out_hw13_1/part-00008\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00009 to out_hw13_1/part-00009\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00010 to out_hw13_1/part-00010\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00014 to out_hw13_1/part-00014\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00015 to out_hw13_1/part-00015\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00011 to out_hw13_1/part-00011\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00012 to out_hw13_1/part-00012\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00013 to out_hw13_1/part-00013\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00016 to out_hw13_1/part-00016\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00017 to out_hw13_1/part-00017\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00022 to out_hw13_1/part-00022\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00021 to out_hw13_1/part-00021\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00018 to out_hw13_1/part-00018\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00020 to out_hw13_1/part-00020\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00019 to out_hw13_1/part-00019\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00023 to out_hw13_1/part-00023\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00024 to out_hw13_1/part-00024\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00026 to out_hw13_1/part-00026\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00029 to out_hw13_1/part-00029\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00027 to out_hw13_1/part-00027\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00025 to out_hw13_1/part-00025\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00028 to out_hw13_1/part-00028\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00030 to out_hw13_1/part-00030\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00031 to out_hw13_1/part-00031\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00032 to out_hw13_1/part-00032\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00033 to out_hw13_1/part-00033\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00035 to out_hw13_1/part-00035\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00034 to out_hw13_1/part-00034\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00005 to out_hw13_1/part-00005\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00002 to out_hw13_1/part-00002\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00003 to out_hw13_1/part-00003\n",
      "('A', 0.033, '')\n",
      "('B', 0.384, 'C')\n",
      "('C', 0.343, 'B')\n",
      "('D', 0.039, 'A|B')\n",
      "('E', 0.081, 'B|D|F')\n",
      "('F', 0.039, 'B|E')\n",
      "('G', 0.016, 'B|E')\n",
      "('H', 0.016, 'B|E')\n",
      "('I', 0.016, 'B|E')\n",
      "('J', 0.016, 'E')\n",
      "('K', 0.016, 'E')\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# copying latest script\n",
    "!scp -i ~/rthallam_sa_east.pem ./pagerank_13_1.py hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com:/home/hadoop/src\n",
    "# removing target directory\n",
    "!aws s3 rm s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/ --recursive\n",
    "# launching script\n",
    "!ssh -i ~/rthallam_sa_east.pem hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com /usr/lib/spark/bin/spark-submit --master yarn-cluster /home/hadoop/src/pagerank_13_1.py s3n://ucb-mids-mls-networks/PageRank-test.txt 100 s3n://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "print \"=\"*80\n",
    "print \"Time taken to find page rank of the network = {:.2f} seconds\".format(end_time - start_time)\n",
    "print \"=\"*80\n",
    "\n",
    "print \"Pagerank of the graph is\"\n",
    "!rm -f ./out_hw13_1/part*\n",
    "!aws s3 cp s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/ ./out_hw13_1 --recursive\n",
    "!cat out_hw13_1/part-000* | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:dodgerblue;font:12px\">HW13.2</span></h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:firebrick; font-size: 120%;\"><b>Applying PageRank to the Wikipedia hyperlinks network</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue\">Run your Spark PageRank implementation on the Wikipedia dataset for 10 iterations, and display the top 100 ranked nodes (with alpha = 0.85). <br><br>\n",
    "Run your PageRank implementation on the Wikipedia dataset for 50 iterations, and display the top 100 ranked nodes (with teleportation factor of 0.15). <br><br>\n",
    "Plot the pagerank values for the top 100 pages resulting from the 50 iterations run. Then plot the pagerank values for the same 100 pages that resulted from the 10 iterations run.  Comment on your findings.  Have the top 100 ranked pages changed? Have the pagerank values changed? Explain. <br><br>\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete your job. <br><br>\n",
    "NOTE: Wikipedia data is located on S3 at  <br>\n",
    "-- s3://ucb-mids-mls-networks/wikipedia/ <br>\n",
    "-- s3://ucb-mids-mls-networks/wikipedia/all-pages-indexed-out.txt # Graph <br>\n",
    "-- s3://ucb-mids-mls-networks/wikipedia/indices.txt               # Page titles and page Ids\n",
    "</span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue; font-size:120%\">**Cluster Creation for Wiki Page Rank**</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aws emr create-cluster --name \"rt-hw13\" \\\n",
    "    --release-label emr-4.2.0 \\\n",
    "    --applications Name=Spark \\\n",
    "    --ec2-attributes KeyName=rthallam_sa_east \\\n",
    "    --log-uri s3://ucb-mids-mls-rajeshthallam/hw13/logs \\\n",
    "    --instance-type m3.xlarge  \\\n",
    "    --instance-count 10 \\\n",
    "    --use-default-roles \\\n",
    "    --configurations file://./emr_config_spark_rt.json \\\n",
    "    --bootstrap-actions Path=s3://ucb-mids-mls-rajeshthallam/bootstrap_actions.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue; font-size:120%\">**Running with indexed toy data set**</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pagerank_13_1.py                              100% 3220     3.1KB/s   00:00    \n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/_SUCCESS\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00005\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00010\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00009\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00011\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00012\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00013\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00015\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00014\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00017\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00016\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00019\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00020\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00002\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00007\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00001\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00021\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00022\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00018\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00023\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00024\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00025\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00026\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00027\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00030\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00028\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00032\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00031\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00008\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00033\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00029\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00035\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00034\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00000\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00004\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00003\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00006\n",
      "15/12/07 23:34:12 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "15/12/07 23:34:12 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-32-212.sa-east-1.compute.internal/172.31.32.212:8032\n",
      "15/12/07 23:34:12 INFO yarn.Client: Requesting a new application from cluster with 9 NodeManagers\n",
      "15/12/07 23:34:12 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (11520 MB per container)\n",
      "15/12/07 23:34:12 INFO yarn.Client: Will allocate AM container, with 1408 MB memory including 384 MB overhead\n",
      "15/12/07 23:34:12 INFO yarn.Client: Setting up container launch context for our AM\n",
      "15/12/07 23:34:12 INFO yarn.Client: Setting up the launch environment for our AM container\n",
      "15/12/07 23:34:12 INFO yarn.Client: Preparing resources for our AM container\n",
      "15/12/07 23:34:13 INFO yarn.Client: Uploading resource file:/usr/lib/spark/lib/spark-assembly-1.5.2-hadoop2.6.0-amzn-2.jar -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0027/spark-assembly-1.5.2-hadoop2.6.0-amzn-2.jar\n",
      "15/12/07 23:34:13 INFO metrics.MetricsSaver: MetricsConfigRecord disabledInCluster: false instanceEngineCycleSec: 60 clusterEngineCycleSec: 60 disableClusterEngine: false maxMemoryMb: 3072 maxInstanceCount: 500 lastModified: 1449482533009 \n",
      "15/12/07 23:34:13 INFO metrics.MetricsSaver: Created MetricsSaver j-KBN00RIHUZBE:i-d5952e37:SparkSubmit:26959 period:60 /mnt/var/em/raw/i-d5952e37_20151207_SparkSubmit_26959_raw.bin\n",
      "15/12/07 23:34:15 INFO metrics.MetricsSaver: 1 aggregated HDFSWriteDelay 2650 raw values into 1 aggregated values, total 1\n",
      "15/12/07 23:34:15 INFO yarn.Client: Uploading resource file:/home/hadoop/src/pagerank_13_1.py -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0027/pagerank_13_1.py\n",
      "15/12/07 23:34:15 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0027/pyspark.zip\n",
      "15/12/07 23:34:15 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.8.2.1-src.zip -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0027/py4j-0.8.2.1-src.zip\n",
      "15/12/07 23:34:15 INFO yarn.Client: Uploading resource file:/tmp/spark-07519b58-7cf3-4b2c-89ab-78820cae8125/__spark_conf__8855762266435351902.zip -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0027/__spark_conf__8855762266435351902.zip\n",
      "15/12/07 23:34:15 INFO spark.SecurityManager: Changing view acls to: hadoop\n",
      "15/12/07 23:34:15 INFO spark.SecurityManager: Changing modify acls to: hadoop\n",
      "15/12/07 23:34:15 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hadoop); users with modify permissions: Set(hadoop)\n",
      "15/12/07 23:34:15 INFO yarn.Client: Submitting application 27 to ResourceManager\n",
      "15/12/07 23:34:15 INFO impl.YarnClientImpl: Submitted application application_1449482525945_0027\n",
      "15/12/07 23:34:16 INFO yarn.Client: Application report for application_1449482525945_0027 (state: ACCEPTED)\n",
      "15/12/07 23:34:16 INFO yarn.Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: N/A\n",
      "\t ApplicationMaster host: N/A\n",
      "\t ApplicationMaster RPC port: -1\n",
      "\t queue: default\n",
      "\t start time: 1449531255431\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://ip-172-31-32-212.sa-east-1.compute.internal:20888/proxy/application_1449482525945_0027/\n",
      "\t user: hadoop\n",
      "15/12/07 23:34:17 INFO yarn.Client: Application report for application_1449482525945_0027 (state: ACCEPTED)\n",
      "15/12/07 23:34:18 INFO yarn.Client: Application report for application_1449482525945_0027 (state: ACCEPTED)\n",
      "15/12/07 23:34:19 INFO yarn.Client: Application report for application_1449482525945_0027 (state: ACCEPTED)\n",
      "15/12/07 23:34:20 INFO yarn.Client: Application report for application_1449482525945_0027 (state: ACCEPTED)\n",
      "15/12/07 23:34:21 INFO yarn.Client: Application report for application_1449482525945_0027 (state: ACCEPTED)\n",
      "15/12/07 23:34:22 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:22 INFO yarn.Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: N/A\n",
      "\t ApplicationMaster host: 172.31.42.131\n",
      "\t ApplicationMaster RPC port: 0\n",
      "\t queue: default\n",
      "\t start time: 1449531255431\n",
      "\t final status: UNDEFINED\n",
      "\t tracking URL: http://ip-172-31-32-212.sa-east-1.compute.internal:20888/proxy/application_1449482525945_0027/\n",
      "\t user: hadoop\n",
      "15/12/07 23:34:23 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:24 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:25 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:26 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:27 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:28 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:29 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:30 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:31 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:32 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:33 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:34 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:35 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:36 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:37 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:38 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:39 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:40 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:41 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:42 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:43 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:44 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:45 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:46 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:47 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:48 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:49 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:50 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:51 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:52 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:53 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:54 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:55 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:56 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:57 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:58 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:34:59 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:00 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:01 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:02 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:03 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:04 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:05 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:06 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:07 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:08 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:09 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:10 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:11 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:12 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:13 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:14 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:15 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:16 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:17 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:18 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:19 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:20 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:21 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:22 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:23 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:24 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:25 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:26 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:27 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:28 INFO yarn.Client: Application report for application_1449482525945_0027 (state: RUNNING)\n",
      "15/12/07 23:35:29 INFO yarn.Client: Application report for application_1449482525945_0027 (state: FINISHED)\n",
      "15/12/07 23:35:29 INFO yarn.Client: \n",
      "\t client token: N/A\n",
      "\t diagnostics: N/A\n",
      "\t ApplicationMaster host: 172.31.42.131\n",
      "\t ApplicationMaster RPC port: 0\n",
      "\t queue: default\n",
      "\t start time: 1449531255431\n",
      "\t final status: SUCCEEDED\n",
      "\t tracking URL: http://ip-172-31-32-212.sa-east-1.compute.internal:20888/proxy/application_1449482525945_0027/history/application_1449482525945_0027/1\n",
      "\t user: hadoop\n",
      "15/12/07 23:35:29 INFO yarn.Client: Deleting staging directory .sparkStaging/application_1449482525945_0027\n",
      "15/12/07 23:35:29 INFO util.ShutdownHookManager: Shutdown hook called\n",
      "15/12/07 23:35:29 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-07519b58-7cf3-4b2c-89ab-78820cae8125\n",
      "================================================================================\n",
      "Time taken to find page rank of the network = 98.21 seconds\n",
      "================================================================================\n",
      "Pagerank of the graph is\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00000 to out_hw13_1/part-00000\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00001 to out_hw13_1/part-00001\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00003 to out_hw13_1/part-00003\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00005 to out_hw13_1/part-00005\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00007 to out_hw13_1/part-00007\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00008 to out_hw13_1/part-00008\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00002 to out_hw13_1/part-00002\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/_SUCCESS to out_hw13_1/_SUCCESS\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00009 to out_hw13_1/part-00009\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00010 to out_hw13_1/part-00010\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00011 to out_hw13_1/part-00011\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00004 to out_hw13_1/part-00004\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00006 to out_hw13_1/part-00006\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00015 to out_hw13_1/part-00015\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00014 to out_hw13_1/part-00014\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00017 to out_hw13_1/part-00017\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00020 to out_hw13_1/part-00020\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00023 to out_hw13_1/part-00023\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00021 to out_hw13_1/part-00021\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00024 to out_hw13_1/part-00024\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00022 to out_hw13_1/part-00022\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00012 to out_hw13_1/part-00012\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00025 to out_hw13_1/part-00025\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00026 to out_hw13_1/part-00026\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00028 to out_hw13_1/part-00028\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00030 to out_hw13_1/part-00030\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00027 to out_hw13_1/part-00027\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00031 to out_hw13_1/part-00031\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00032 to out_hw13_1/part-00032\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00033 to out_hw13_1/part-00033\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00029 to out_hw13_1/part-00029\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00034 to out_hw13_1/part-00034\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00035 to out_hw13_1/part-00035\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00013 to out_hw13_1/part-00013\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00016 to out_hw13_1/part-00016\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00018 to out_hw13_1/part-00018\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/part-00019 to out_hw13_1/part-00019\n",
      "('10', 0.016, 5)\n",
      "('1', 0.033, '')\n",
      "('11', 0.016, 5)\n",
      "('2', 0.384, 3)\n",
      "('3', 0.343, 2)\n",
      "('4', 0.039, '1|2')\n",
      "('5', 0.081, '2|4|6')\n",
      "('6', 0.039, '2|5')\n",
      "('7', 0.016, '2|5')\n",
      "('8', 0.016, '2|5')\n",
      "('9', 0.016, '2|5')\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# copying latest script\n",
    "!scp -i ~/rthallam_sa_east.pem ./pagerank_13_1.py hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com:/home/hadoop/src\n",
    "# removing target directory\n",
    "!aws s3 rm s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/ --recursive\n",
    "# launching script\n",
    "!ssh -i ~/rthallam_sa_east.pem hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com /usr/lib/spark/bin/spark-submit --master yarn-cluster /home/hadoop/src/pagerank_13_1.py s3n://ucb-mids-mls-rajeshthallam/hw13/PageRank-test_indexed.txt 100 s3n://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "print \"=\"*80\n",
    "print \"Time taken to find page rank of the network = {:.2f} seconds\".format(end_time - start_time)\n",
    "print \"=\"*80\n",
    "\n",
    "print \"Pagerank of the graph is\"\n",
    "!rm -f ./out_hw13_1/part*\n",
    "!aws s3 cp s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_1/ ./out_hw13_1 --recursive\n",
    "!cat out_hw13_1/part-000* | sort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue; font-size:120%\">**Pagerank on Wikipedia data set**</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pagerank_13_2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pagerank_13_2.py\n",
    "#!/usr/bin/python\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import sys\n",
    "import ast\n",
    "from operator import add\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "def pagerank_init(line):\n",
    "    # initialize page rank as 1/N for all nodes with \n",
    "    # outgoing links and emit with graph structure\n",
    "    node, ol = line.split('\\t')\n",
    "    neighbors = '|'.join(ast.literal_eval(ol).keys())\n",
    "    yield node.encode('utf-8'), [1/N, neighbors]\n",
    "\n",
    "def distribute(node, rank_links):\n",
    "    \"\"\"Calculates URL contributions to the rank of other URLs.\"\"\"\n",
    "    r = rank_links[0]\n",
    "    links = rank_links[1]\n",
    "\n",
    "    ol = str(links).split('|')\n",
    "    Ni = len(ol)\n",
    "\n",
    "    # if the node is for dangling (i.e. no outgoing link),\n",
    "    # emit the loss to redistribute to all the incoming\n",
    "    # links to the dangling node\n",
    "    if (Ni == 1 and ol[0] == '') or Ni == 0:\n",
    "        yield 'DANGLING', r\n",
    "    else:\n",
    "        r_new = float(r)/float(Ni)\n",
    "        for l in ol:\n",
    "            yield l, r_new\n",
    "\n",
    "    # recover graph structure\n",
    "    if links <> '':\n",
    "        yield node, links\n",
    "\n",
    "# update pagerank by combining the mass\n",
    "def combine_mass(rank_links):\n",
    "    r = 0.0\n",
    "    out = ''\n",
    "\n",
    "    for i in rank_links.split('~'):\n",
    "        try:\n",
    "            i = ast.literal_eval(i)\n",
    "            if type(i) == float:\n",
    "                r += i\n",
    "            else:\n",
    "                out = i if i else out\n",
    "        except:\n",
    "            out = i if i else out\n",
    "            pass\n",
    "\n",
    "    return str(r) + '~' + str(out)\n",
    "\n",
    "def update_pagerank(node, rank_links, loss, N, a = 0.15):\n",
    "    r = 0.0\n",
    "    out_links = \"\"    \n",
    "        \n",
    "    for i in str(rank_links).split('~'):\n",
    "        try:\n",
    "            i = ast.literal_eval(i)\n",
    "            if type(i) == float:\n",
    "                r = float(i)\n",
    "            else:\n",
    "                out_links = i if i else out_links\n",
    "        except:\n",
    "            out_links = i if i else out_links\n",
    "            pass\n",
    "    \n",
    "    r_new = a * (1/N) + (1-a) * (loss/N + r)\n",
    "    return node, [r_new, out_links]\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 4:\n",
    "        print(\"Usage: pagerank <source_file> <iterations> <target_file>\")\n",
    "        exit(-1)\n",
    "\n",
    "    # Initialize the spark context.\n",
    "    sc = SparkContext(appName=\"WikiPageRank\")\n",
    "\n",
    "    lines = sc.textFile(sys.argv[1], 1)\n",
    "    N = 15192277.0\n",
    "    #N = 11.0\n",
    "    D = 0.85\n",
    "    a = 0.15\n",
    "    \n",
    "    # parse and initialize pagerank\n",
    "    ranks = lines.flatMap(lambda pages: pagerank_init(pages))\n",
    "    \n",
    "    for iteration in range(int(sys.argv[2])):\n",
    "        # contribution from each page\n",
    "        contribs = ranks \\\n",
    "                    .flatMap(lambda (node, rank_links): distribute(node, rank_links)) \\\n",
    "                    .reduceByKey(lambda prev, curr: combine_mass(str(prev) + '~' + str(curr))).cache()\n",
    "        \n",
    "        # find dangling mass\n",
    "        dangling_nodes = contribs.lookup('DANGLING')\n",
    "        dangling_mass = 0.0 if len(dangling_nodes) == 0 else float(str(dangling_nodes[0]).strip('~'))\n",
    "\n",
    "        # update page rank\n",
    "        ranks_new = contribs \\\n",
    "                    .filter(lambda (k, v): k != 'DANGLING') \\\n",
    "                    .map(lambda (node, rank_links): update_pagerank(node, rank_links, dangling_mass, N, a))\n",
    "        ranks = ranks_new.cache()\n",
    "        \n",
    "        if iteration in [9, 49]:\n",
    "            top_100 = ranks.top(100, key = lambda (node, rank_links): rank_links[0])\n",
    "            sc.parallelize(top_100) \\\n",
    "                .map(lambda (node, rank_links): str(node) + '|' + str(rank_links[0])) \\\n",
    "                .saveAsTextFile(sys.argv[3] + \"/\" + str(iteration))\n",
    "        \n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue; font-size:120%\">**Running Pagerank on Wikipedia data set for 10 iterations**</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# copying latest script\n",
    "!scp -i ~/rthallam_sa_east.pem ./pagerank_13_2.py hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com:/home/hadoop/src\n",
    "# removing target directory\n",
    "!aws s3 rm s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/ --recursive\n",
    "# launching script\n",
    "!ssh -i ~/rthallam_sa_east.pem hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com /usr/lib/spark/bin/spark-submit --master yarn-cluster /home/hadoop/src/pagerank_13_2.py s3n://ucb-mids-mls-networks/wikipedia/all-pages-indexed-out.txt 10 s3n://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/ > ./hw_13_2_iter10.log 2>&1\n",
    "#!ssh -i ~/rthallam_sa_east.pem hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com /usr/lib/spark/bin/spark-submit --master yarn-cluster /home/hadoop/src/pagerank_13_2.py s3n://ucb-mids-mls-rajeshthallam/hw13/PageRank-test_indexed.txt 10 s3n://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "print \"=\"*80\n",
    "print \"Time taken to find page rank of the network = {:.2f} seconds\".format(end_time - start_time)\n",
    "print \"=\"*80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "pagerank_13_2.py                              100% 3463     3.4KB/s   00:00    \n",
    "15/12/08 02:31:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
    "15/12/08 02:31:24 INFO client.RMProxy: Connecting to ResourceManager at ip-172-31-32-212.sa-east-1.compute.internal/172.31.32.212:8032\n",
    "15/12/08 02:31:24 INFO yarn.Client: Requesting a new application from cluster with 9 NodeManagers\n",
    "15/12/08 02:31:24 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (11520 MB per container)\n",
    "15/12/08 02:31:24 INFO yarn.Client: Will allocate AM container, with 1408 MB memory including 384 MB overhead\n",
    "15/12/08 02:31:24 INFO yarn.Client: Setting up container launch context for our AM\n",
    "15/12/08 02:31:24 INFO yarn.Client: Setting up the launch environment for our AM container\n",
    "15/12/08 02:31:24 INFO yarn.Client: Preparing resources for our AM container\n",
    "15/12/08 02:31:24 INFO yarn.Client: Uploading resource file:/usr/lib/spark/lib/spark-assembly-1.5.2-hadoop2.6.0-amzn-2.jar -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0035/spark-assembly-1.5.2-hadoop2.6.0-amzn-2.jar\n",
    "15/12/08 02:31:25 INFO metrics.MetricsSaver: MetricsConfigRecord disabledInCluster: false instanceEngineCycleSec: 60 clusterEngineCycleSec: 60 disableClusterEngine: false maxMemoryMb: 3072 maxInstanceCount: 500 lastModified: 1449482533009 \n",
    "15/12/08 02:31:25 INFO metrics.MetricsSaver: Created MetricsSaver j-KBN00RIHUZBE:i-d5952e37:SparkSubmit:03344 period:60 /mnt/var/em/raw/i-d5952e37_20151208_SparkSubmit_03344_raw.bin\n",
    "15/12/08 02:31:26 INFO metrics.MetricsSaver: 1 aggregated HDFSWriteDelay 1152 raw values into 1 aggregated values, total 1\n",
    "15/12/08 02:31:26 INFO yarn.Client: Uploading resource file:/home/hadoop/src/pagerank_13_2.py -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0035/pagerank_13_2.py\n",
    "15/12/08 02:31:26 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0035/pyspark.zip\n",
    "15/12/08 02:31:26 INFO yarn.Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.8.2.1-src.zip -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0035/py4j-0.8.2.1-src.zip\n",
    "15/12/08 02:31:26 INFO yarn.Client: Uploading resource file:/tmp/spark-3c2f91b6-6d4b-480d-a130-bd8c5bc68322/__spark_conf__8771859733817262757.zip -> hdfs://ip-172-31-32-212.sa-east-1.compute.internal:8020/user/hadoop/.sparkStaging/application_1449482525945_0035/__spark_conf__8771859733817262757.zip\n",
    "15/12/08 02:31:26 INFO spark.SecurityManager: Changing view acls to: hadoop\n",
    "15/12/08 02:31:26 INFO spark.SecurityManager: Changing modify acls to: hadoop\n",
    "15/12/08 02:31:26 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hadoop); users with modify permissions: Set(hadoop)\n",
    "15/12/08 02:31:26 INFO yarn.Client: Submitting application 35 to ResourceManager\n",
    "15/12/08 02:31:26 INFO impl.YarnClientImpl: Submitted application application_1449482525945_0035\n",
    "15/12/08 02:31:27 INFO yarn.Client: Application report for application_1449482525945_0035 (state: ACCEPTED)\n",
    "...\n",
    "15/12/08 04:25:32 INFO yarn.Client: Application report for application_1449482525945_0035 (state: RUNNING)\n",
    "15/12/08 04:25:33 INFO yarn.Client: Application report for application_1449482525945_0035 (state: FINISHED)\n",
    "15/12/08 04:25:33 INFO yarn.Client: \n",
    "\t client token: N/A\n",
    "\t diagnostics: N/A\n",
    "\t ApplicationMaster host: 172.31.42.131\n",
    "\t ApplicationMaster RPC port: 0\n",
    "\t queue: default\n",
    "\t start time: 1449541886956\n",
    "\t final status: SUCCEEDED\n",
    "\t tracking URL: http://ip-172-31-32-212.sa-east-1.compute.internal:20888/proxy/application_1449482525945_0035/history/application_1449482525945_0035/1\n",
    "\t user: hadoop\n",
    "15/12/08 04:25:33 INFO util.ShutdownHookManager: Shutdown hook called\n",
    "15/12/08 04:25:33 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-3c2f91b6-6d4b-480d-a130-bd8c5bc68322\n",
    "================================================================================\n",
    "Time taken to find page rank of the network = 6866.21 seconds\n",
    "================================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/_SUCCESS to out_hw13_2/iter_10/_SUCCESS\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00002 to out_hw13_2/iter_10/part-00002\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00000 to out_hw13_2/iter_10/part-00000\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00004 to out_hw13_2/iter_10/part-00004\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00009 to out_hw13_2/iter_10/part-00009\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00003 to out_hw13_2/iter_10/part-00003\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00005 to out_hw13_2/iter_10/part-00005\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00006 to out_hw13_2/iter_10/part-00006\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00007 to out_hw13_2/iter_10/part-00007\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00001 to out_hw13_2/iter_10/part-00001\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00010 to out_hw13_2/iter_10/part-00010\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00011 to out_hw13_2/iter_10/part-00011\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00008 to out_hw13_2/iter_10/part-00008\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00013 to out_hw13_2/iter_10/part-00013\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00012 to out_hw13_2/iter_10/part-00012\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00014 to out_hw13_2/iter_10/part-00014\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00015 to out_hw13_2/iter_10/part-00015\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00021 to out_hw13_2/iter_10/part-00021\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00017 to out_hw13_2/iter_10/part-00017\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00019 to out_hw13_2/iter_10/part-00019\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00020 to out_hw13_2/iter_10/part-00020\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00016 to out_hw13_2/iter_10/part-00016\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00022 to out_hw13_2/iter_10/part-00022\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00023 to out_hw13_2/iter_10/part-00023\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00024 to out_hw13_2/iter_10/part-00024\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00018 to out_hw13_2/iter_10/part-00018\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00025 to out_hw13_2/iter_10/part-00025\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00030 to out_hw13_2/iter_10/part-00030\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00031 to out_hw13_2/iter_10/part-00031\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00032 to out_hw13_2/iter_10/part-00032\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00028 to out_hw13_2/iter_10/part-00028\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00029 to out_hw13_2/iter_10/part-00029\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00027 to out_hw13_2/iter_10/part-00027\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00026 to out_hw13_2/iter_10/part-00026\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00033 to out_hw13_2/iter_10/part-00033\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00034 to out_hw13_2/iter_10/part-00034\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/part-00035 to out_hw13_2/iter_10/part-00035\n",
      "13455888|0.00124386335387\n",
      "1184351|0.000586194420448\n",
      "4695850|0.000547761527379\n",
      "5051368|0.000491622780828\n",
      "1384888|0.000398020431356\n",
      "6113490|0.000392924911541\n",
      "2437837|0.000380263755056\n",
      "7902219|0.000379339642339\n",
      "6076759|0.000368423441293\n",
      "13425865|0.000363696668566\n"
     ]
    }
   ],
   "source": [
    "!rm -f ./out_hw13_2/iter_10/part*\n",
    "!aws s3 cp s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/9/ ./out_hw13_2/iter_10/ --recursive\n",
    "!cat ./out_hw13_2/iter_10/part* > ./out_hw13_2/top100_pr_10iter.txt\n",
    "!head ./out_hw13_2/top100_pr_10iter.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue; font-size:120%\">**Running Pagerank on Wikipedia data set for 50 iterations**</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# copying latest script\n",
    "!scp -i ~/rthallam_sa_east.pem ./pagerank_13_2.py hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com:/home/hadoop/src\n",
    "# removing target directory\n",
    "!aws s3 rm s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/ --recursive\n",
    "# launching script\n",
    "!ssh -i ~/rthallam_sa_east.pem hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com /usr/lib/spark/bin/spark-submit --master yarn-cluster /home/hadoop/src/pagerank_13_2.py s3n://ucb-mids-mls-networks/wikipedia/all-pages-indexed-out.txt 50 s3n://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/ > ./hw_13_2_iter10.log 2>&1\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "print \"=\"*80\n",
    "print \"Time taken to find page rank of the network = {:.2f} seconds\".format(end_time - start_time)\n",
    "print \"=\"*80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table> \n",
    "<caption><b>Cluster Configuration and Run Time</b></caption>\n",
    "<tr><td><b>Cluster Size</b></td><td>9 mx.large (WORKERS) and 1 mx.large (MASTER)</td></tr>\n",
    "<tr><td><b>Run time</b></td><td>10hours 10 minutes</td></tr>\n",
    "</table>\n",
    "\n",
    "![Pagerank with 50 iterations](./hw13_2_w_50_iter.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00001 to out_hw13_2/iter_50/part-00001\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00000 to out_hw13_2/iter_50/part-00000\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/_SUCCESS to out_hw13_2/iter_50/_SUCCESS\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00002 to out_hw13_2/iter_50/part-00002\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00004 to out_hw13_2/iter_50/part-00004\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00006 to out_hw13_2/iter_50/part-00006\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00003 to out_hw13_2/iter_50/part-00003\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00005 to out_hw13_2/iter_50/part-00005\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00007 to out_hw13_2/iter_50/part-00007\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00010 to out_hw13_2/iter_50/part-00010\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00009 to out_hw13_2/iter_50/part-00009\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00011 to out_hw13_2/iter_50/part-00011\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00008 to out_hw13_2/iter_50/part-00008\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00013 to out_hw13_2/iter_50/part-00013\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00014 to out_hw13_2/iter_50/part-00014\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00016 to out_hw13_2/iter_50/part-00016\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00015 to out_hw13_2/iter_50/part-00015\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00021 to out_hw13_2/iter_50/part-00021\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00019 to out_hw13_2/iter_50/part-00019\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00018 to out_hw13_2/iter_50/part-00018\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00012 to out_hw13_2/iter_50/part-00012\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00022 to out_hw13_2/iter_50/part-00022\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00020 to out_hw13_2/iter_50/part-00020\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00017 to out_hw13_2/iter_50/part-00017\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00023 to out_hw13_2/iter_50/part-00023\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00024 to out_hw13_2/iter_50/part-00024\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00026 to out_hw13_2/iter_50/part-00026\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00029 to out_hw13_2/iter_50/part-00029\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00027 to out_hw13_2/iter_50/part-00027\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00030 to out_hw13_2/iter_50/part-00030\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00032 to out_hw13_2/iter_50/part-00032\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00028 to out_hw13_2/iter_50/part-00028\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00031 to out_hw13_2/iter_50/part-00031\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00025 to out_hw13_2/iter_50/part-00025\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00033 to out_hw13_2/iter_50/part-00033\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00034 to out_hw13_2/iter_50/part-00034\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/part-00035 to out_hw13_2/iter_50/part-00035\n",
      "13455888|0.00146123288559\n",
      "1184351|0.000665898159074\n",
      "4695850|0.000639539383074\n",
      "5051368|0.000574642371439\n",
      "1384888|0.000450045113107\n",
      "2437837|0.000446570248047\n",
      "6113490|0.000444554733289\n",
      "7902219|0.000443782019836\n",
      "13425865|0.000433037750573\n",
      "6076759|0.000427618817211\n"
     ]
    }
   ],
   "source": [
    "!rm -f ./out_hw13_2/iter_50/part*\n",
    "!aws s3 cp s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/49/ ./out_hw13_2/iter_50/ --recursive\n",
    "!cat ./out_hw13_2/iter_50/part* > ./out_hw13_2/top100_pr_50iter.txt\n",
    "!head ./out_hw13_2/top100_pr_50iter.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue; font-size:120%\">**Results**</span><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "from tabulate import tabulate\n",
    "import sys\n",
    "import os\n",
    "\n",
    "LOOKUP = os.path.join('out_hw13_2', 'indices.txt')\n",
    "TOP10_ITER = os.path.join('out_hw13_2', 'top100_pr_10iter.txt')\n",
    "TOP50_ITER = os.path.join('out_hw13_2', 'top100_pr_50iter.txt')\n",
    "\n",
    "lookup = { key.strip():value.strip() for value, key, v1, v2 in (line.split(\"\\t\") for line in open(LOOKUP).read().strip().split('\\n')) }\n",
    "pr_10 = [ (page, float(rank)) for page, rank in (line.split(\"|\") for line in open(TOP10_ITER).read().strip().split('\\n')) ]\n",
    "pr_50 = [ (page, float(rank)) for page, rank in (line.split(\"|\") for line in open(TOP50_ITER).read().strip().split('\\n')) ]\n",
    "\n",
    "pr_10 = sorted(pr_10, key=lambda x: -x[1])\n",
    "pr_50 = sorted(pr_50, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Comparing Top 100 pages with 10 and 50 iterations\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  #  Page (10)                                   Rank (10)  Page (50)                                   Rank (50)\n",
      "---  ----------------------------------------  -----------  ----------------------------------------  -----------\n",
      "  1  United States                             0.00124386   United States                             0.00146123\n",
      "  2  Animal                                    0.000586194  Animal                                    0.000665898\n",
      "  3  France                                    0.000547762  France                                    0.000639539\n",
      "  4  Germany                                   0.000491623  Germany                                   0.000574642\n",
      "  5  Arthropod                                 0.00039802   Arthropod                                 0.000450045\n",
      "  6  Insect                                    0.000392925  Canada                                    0.00044657\n",
      "  7  Canada                                    0.000380264  Insect                                    0.000444555\n",
      "  8  List of sovereign states                  0.00037934   List of sovereign states                  0.000443782\n",
      "  9  India                                     0.000368423  United Kingdom                            0.000433038\n",
      " 10  United Kingdom                            0.000363697  India                                     0.000427619\n",
      " 11  England                                   0.000361869  England                                   0.000423324\n",
      " 12  Iran                                      0.000343762  Iran                                      0.000397745\n",
      " 13  World War II                              0.000324042  World War II                              0.000385394\n",
      " 14  Poland                                    0.000309507  Poland                                    0.000362587\n",
      " 15  village                                   0.000300406  village                                   0.000343523\n",
      " 16  Countries of the world                    0.000294427  Countries of the world                    0.000337984\n",
      " 17  List of countries                         0.000285808  Japan                                     0.000329149\n",
      " 18  Japan                                     0.000281883  Italy                                     0.000328921\n",
      " 19  Italy                                     0.00028006   List of countries                         0.000326141\n",
      " 20  Australia                                 0.000277023  Australia                                 0.000325039\n",
      " 21  Lepidoptera                               0.000272473  Voivodeships of Poland                    0.000312619\n",
      " 22  National Register of Historic Places      0.000271264  National Register of Historic Places      0.000309512\n",
      " 23  Voivodeships of Poland                    0.000270559  Lepidoptera                               0.000307927\n",
      " 24  Powiat                                    0.000262697  Powiat                                    0.00030306\n",
      " 25  Gmina                                     0.000258066  Gmina                                     0.000297489\n",
      " 26  London                                    0.000238864  The New York Times                        0.000285961\n",
      " 27  The New York Times                        0.000235059  London                                    0.000283553\n",
      " 28  English language                          0.000226878  English language                          0.00026899\n",
      " 29  China                                     0.000222865  China                                     0.000263952\n",
      " 30  Russia                                    0.000222504  Russia                                    0.000260927\n",
      " 31  Departments of France                     0.000221376  New York City                             0.000257634\n",
      " 32  moth                                      0.000217131  Departments of France                     0.00025492\n",
      " 33  Communes of France                        0.000216128  Spain                                     0.000250967\n",
      " 34  New York City                             0.000215487  Communes of France                        0.000248627\n",
      " 35  Spain                                     0.000214133  moth                                      0.000245322\n",
      " 36  Brazil                                    0.000210596  Brazil                                    0.000244669\n",
      " 37  Association football                      0.000205145  Association football                      0.000238598\n",
      " 38  association football                      0.000200794  association football                      0.000233255\n",
      " 39  Counties of Iran                          0.000188894  California                                0.000220583\n",
      " 40  Provinces of Iran                         0.000188522  Counties of Iran                          0.000214916\n",
      " 41  California                                0.000187948  Provinces of Iran                         0.000214506\n",
      " 42  Romania                                   0.000182176  Central European Time                     0.000211159\n",
      " 43  Bakhsh                                    0.000182139  Romania                                   0.000211144\n",
      " 44  Central European Time                     0.000181422  Bakhsh                                    0.000206994\n",
      " 45  Rural Districts of Iran                   0.000178703  Sweden                                    0.000203257\n",
      " 46  Sweden                                    0.00017355   Rural Districts of Iran                   0.000202494\n",
      " 47  Private Use Areas                         0.000170599  Netherlands                               0.000196969\n",
      " 48  Netherlands                               0.000166894  Private Use Areas                         0.000191359\n",
      " 49  Iran Standard Time                        0.000164328  World War I                               0.000190737\n",
      " 50  Central European Summer Time              0.000161538  New York                                  0.000188127\n",
      " 51  Mexico                                    0.000160058  Central European Summer Time              0.000187982\n",
      " 52  World War I                               0.000159926  Mexico                                    0.000187003\n",
      " 53  New York                                  0.000158606  Iran Standard Time                        0.000186699\n",
      " 54  Hangul                                    0.000158491  AllMusic                                  0.000185186\n",
      " 55  Iran Daylight Time                        0.000157637  Iran Daylight Time                        0.000178718\n",
      " 56  AllMusic                                  0.000156555  Hangul                                    0.000178283\n",
      " 57  gene                                      0.000148917  Scotland                                  0.000173309\n",
      " 58  Scotland                                  0.00014692   gene                                      0.000169453\n",
      " 59  Allmusic                                  0.000143579  Soviet Union                              0.00016761\n",
      " 60  Norway                                    0.000142929  Norway                                    0.000167178\n",
      " 61  Soviet Union                              0.00013989   Allmusic                                  0.000165367\n",
      " 62  New Zealand                               0.00013706   Paris                                     0.000160658\n",
      " 63  Plant                                     0.000136014  New Zealand                               0.000160488\n",
      " 64  Turkey                                    0.000135682  Turkey                                    0.000158972\n",
      " 65  Paris                                     0.000135243  Plant                                     0.000157586\n",
      " 66  Geographic Names Information System       0.000133383  Geographic Names Information System       0.000155239\n",
      " 67  Romanize                                  0.000131861  Switzerland                               0.000154895\n",
      " 68  Switzerland                               0.000131247  Los Angeles                               0.000153252\n",
      " 69  Los Angeles                               0.000128151  Romanize                                  0.000148809\n",
      " 70  United States Census Bureau               0.000124647  United States Census Bureau               0.000147822\n",
      " 71  Angiosperms                               0.000124205  Europe                                    0.000147075\n",
      " 72  Europe                                    0.000123353  Angiosperms                               0.000141818\n",
      " 73  South Africa                              0.00012101   South Africa                              0.000141269\n",
      " 74  census                                    0.000118841  census                                    0.000139036\n",
      " 75  protein                                   0.000118452  Flowering plant                           0.000137617\n",
      " 76  Flowering plant                           0.000117578  Austria                                   0.000136216\n",
      " 77  Austria                                   0.000115767  protein                                   0.000134871\n",
      " 78  U.S. state                                0.000114222  U.S. state                                0.000134712\n",
      " 79  Political divisions of the United States  0.000112744  Argentina                                 0.000130665\n",
      " 80  Argentina                                 0.000111865  Political divisions of the United States  0.00013018\n",
      " 81  Chordate                                  0.000110881  population density                        0.000130008\n",
      " 82  population density                        0.000110056  Catholic Church                           0.000128378\n",
      " 83  Belgium                                   0.00010736   Chordate                                  0.000128179\n",
      " 84  BBC                                       0.000105791  BBC                                       0.000127291\n",
      " 85  Catholic Church                           0.00010564   Belgium                                   0.000127124\n",
      " 86  Chicago                                   0.000103702  Chicago                                   0.000124078\n",
      " 87  Pakistan                                  0.000103113  Washington, D.C.                          0.000120905\n",
      " 88  Washington, D.C.                          9.98312e-05  Pakistan                                  0.000120217\n",
      " 89  genus                                     9.88173e-05  Finland                                   0.000115754\n",
      " 90  Finland                                   9.86714e-05  The Guardian                              0.000114478\n",
      " 91  species                                   9.79067e-05  Latin                                     0.000114443\n",
      " 92  Eastern European Time                     9.73869e-05  Ontario                                   0.000114276\n",
      " 93  Ontario                                   9.70987e-05  Czech Republic                            0.000113568\n",
      " 94  football (soccer)                         9.66824e-05  Philippines                               0.00011324\n",
      " 95  Eudicots                                  9.65718e-05  Denmark                                   0.00011321\n",
      " 96  Czech Republic                            9.64946e-05  Greece                                    0.000113167\n",
      " 97  Philippines                               9.636e-05    genus                                     0.00011289\n",
      " 98  Greece                                    9.60419e-05  football (soccer)                         0.000112393\n",
      " 99  Denmark                                   9.59984e-05  Hungary                                   0.000112162\n",
      "100  Hungary                                   9.56538e-05  Eastern European Time                     0.000112098\n"
     ]
    }
   ],
   "source": [
    "print \"-\"*100\n",
    "print \"Comparing Top 100 pages with {} and {} iterations\".format(10, 50)\n",
    "print \"-\"*100\n",
    "\n",
    "results = []\n",
    "for i in xrange(100):\n",
    "    results.append([\n",
    "                    i+1, \n",
    "                    lookup.get(pr_10[i][0].replace(\"\\\"\",\"\"), 'NA'),\n",
    "                    pr_10[i][1], \n",
    "                    lookup.get(pr_50[i][0].replace(\"\\\"\",\"\"), 'NA'),\n",
    "                    pr_50[i][1]\n",
    "                    ])\n",
    "\n",
    "print tabulate(results, headers=[\"#\",\"Page (10)\", \"Rank (10)\", \"Page (50)\", \"Rank (50)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8dc043f810>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDgAAAF6CAYAAAD8uOhPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKzgVDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8de0440f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Top 100 Page Ranks - 10 Iterations\")\n",
    "plt.ylabel('Page Rank')\n",
    "plt.plot([pr[1] for pr in pr_10])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.title(\"Top 100 Page Ranks - 50 Iterations\")\n",
    "plt.ylabel('Page Rank')\n",
    "plt.plot([pr[1] for pr in pr_50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue; font-size:120%\">**Report**</span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pages associated with top 100 ranks for both 10 and 50 iterations are almost same though their order is different\n",
    "- Page rank values itself differ between 10 and 50 iterations and with 50 iterations these tend to be relatively higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:dodgerblue;font:12px\">HW13.3</span></h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:firebrick; font-size: 120%;\"><b>Spark GraphX versus your implementation of PageRank</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue \">Run the Spark  GraphX PageRank implementation on the Wikipedia dataset for 10 iterations, and display the top 100 ranked nodes (with alpha = 0.85). <br><br>\n",
    "Run your PageRank implementation on the Wikipedia dataset for 50 iterations, and display the top 100 ranked nodes (with teleportation factor of 0.15). Have the top 100 ranked pages changed? Comment on your findings. Plot both 100 curves.<br><br>\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete this job.<br><br>\n",
    "Put the runtime results of HW13.2 and HW13.3 in a tabular format (with rows corresponding to implemention and columns corresponding to experiment setup (10 iterations, 50 iterations)). Discuss the run times and explaing the differences. <br><br>\n",
    "Plot the pagerank values for the top 100 pages resulting from the 50 iterations run (using GraphX). Then plot the pagerank values for the same 100 pages that resulted from the 50 iterations run of your homegrown pagerank implemnentation.  Comment on your findings.  Have the top 100 ranked pages changed? Have the pagerank values changed? Explain.\n",
    "</span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:firebrick; font-size: 120%;\"><b>TO DO</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "object Pagerank {\n",
    "        def main(args: Array[String]) {\n",
    "        val conf = new SparkConf().setAppName(\"pagerank\")\n",
    "        val sc = new SparkContext(conf)\n",
    "        val graph = GraphLoader.edgeListFile(sc, \"file:/home/hadoop/src/pagerank/followers\")\n",
    "        // Run PageRank\n",
    "        //val ranks = graph.pageRank(10).vertices\n",
    "        val ranks = graph.pageRank(0.0001).vertices\n",
    "\n",
    "        // Print the result\n",
    "        println(ranks.collect().mkString(\"\\n\"))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name := \"pagerank\"\n",
    "version := \"1.0\"\n",
    "scalaVersion := \"2.10.5\"\n",
    "libraryDependencies ++= Seq(\"org.apache.spark\" %% \"spark-core\" % \"1.5.2\", \"org.apache.spark\" %% \"spark-graphx\" % \"1.5.2\")\n",
    "resolvers += \"Akka Repository\" at \"http://repo.akka.io/releases/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sbt package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/usr/lib/spark/bin/spark-submit --class \"Pagerank\" --master local [4] $(find target -iname \"*.jar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:dodgerblue;font:12px\">HW13.4</span></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:firebrick; font-size: 120%;\"><b>Criteo Phase 2 baseline</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue\">The  Criteo data is located in the following S3 bucket: [criteo-dataset](https://console.aws.amazon.com/s3/home?region=us-west-1#&bucket=criteo-dataset&prefix=) <br><br>\n",
    "Using the training dataset, validation dataset and testing dataset in the Criteo bucket perform the following experiment: <br><br>\n",
    "-- write spark code (borrow from Phase 1 of this project) to train a logistic regression model with the following hyperparamters:<br>\n",
    "-- Number of buckets for hashing: 1,000<br>\n",
    "-- Logistic Regression: no regularization term<br>\n",
    "-- Logistic Regression: step size = 10<br><br>\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete this job.<br><br>\n",
    "Report in tabular form the [AUC value](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) for the Training, Validation, and Testing datasets. Report in tabular form  the logLossTest for the Training, Validation, and Testing datasets. <br><br>\n",
    "Dont forget to put a caption on your tables (above each table).</span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:cornflowerblue; font-size:120%\"><b>Baseline Criteo Dataset using Raw Data</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting criteo_13_4_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile criteo_13_4_1.py\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "import sys\n",
    "from math import log, exp\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "def hashFunction(numBuckets, rawFeats, printMapping=False):\n",
    "    \"\"\"Calculate a feature dictionary for an observation's features based on hashing.\n",
    "\n",
    "    Note:\n",
    "        Use printMapping=True for debug purposes and to better understand how the hashing works.\n",
    "\n",
    "    Args:\n",
    "        numBuckets (int): Number of buckets to use as features.\n",
    "        rawFeats (list of (int, str)): A list of features for an observation.  Represented as\n",
    "            (featureID, value) tuples.\n",
    "        printMapping (bool, optional): If true, the mappings of featureString to index will be\n",
    "            printed.\n",
    "\n",
    "    Returns:\n",
    "        dict of int to float:  The keys will be integers which represent the buckets that the\n",
    "            features have been hashed to.  The value for a given key will contain the count of the\n",
    "            (featureID, value) tuples that have hashed to that key.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for ind, category in rawFeats:\n",
    "        featureString = category + str(ind)\n",
    "        mapping[featureString] = int(int(hashlib.md5(featureString).hexdigest(), 16) % numBuckets)\n",
    "    if(printMapping): print mapping\n",
    "    sparseFeatures = defaultdict(float)\n",
    "    for bucket in mapping.values():\n",
    "        sparseFeatures[bucket] += 1.0\n",
    "    return dict(sparseFeatures)\n",
    "\n",
    "def parseHashPoint(point, numBuckets):\n",
    "    \"\"\"Create a LabeledPoint for this observation using hashing.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest are\n",
    "            features.\n",
    "        numBuckets: The number of buckets to hash to.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: A LabeledPoint with a label (0.0 or 1.0) and a SparseVector of hashed\n",
    "            features.\n",
    "    \"\"\"\n",
    "    parsedPoints = parsePoint(point)\n",
    "    items = point.split(',')\n",
    "    label = items[0]\n",
    "    features = hashFunction(numBuckets, parsedPoints, printMapping=False)\n",
    "    return LabeledPoint(label, SparseVector(numBuckets, features))\n",
    "\n",
    "def parsePoint(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    return [(i, item) for i, item in enumerate(point.split(',')[1:])]\n",
    "    \n",
    "def computeLogLoss(p, y):\n",
    "    \"\"\"Calculates the value of log loss for a given probabilty and label.\n",
    "\n",
    "    Note:\n",
    "        log(0) is undefined, so when p is 0 we need to add a small value (epsilon) to it\n",
    "        and when p is 1 we need to subtract a small value (epsilon) from it.\n",
    "\n",
    "    Args:\n",
    "        p (float): A probabilty between 0 and 1.\n",
    "        y (int): A label.  Takes on the values 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "        float: The log loss value.\n",
    "    \"\"\"\n",
    "    epsilon = 10e-12\n",
    "    if p == 0:\n",
    "        p = p + epsilon\n",
    "    if p == 1:\n",
    "        p = p - epsilon\n",
    "    return -(y * log(p) + (1-y) * log(1-p))\n",
    "\n",
    "def getP(x, w, intercept):\n",
    "    \"\"\"Calculate the probability for an observation given a set of weights and intercept.\n",
    "\n",
    "    Note:\n",
    "        We'll bound our raw prediction between 20 and -20 for numerical purposes.\n",
    "\n",
    "    Args:\n",
    "        x (SparseVector): A vector with values of 1.0 for features that exist in this\n",
    "            observation and 0.0 otherwise.\n",
    "        w (DenseVector): A vector of weights (betas) for the model.\n",
    "        intercept (float): The model's intercept.\n",
    "\n",
    "    Returns:\n",
    "        float: A probability between 0 and 1.\n",
    "    \"\"\"\n",
    "    rawPrediction = x.dot(w) + intercept\n",
    "\n",
    "    # Bound the raw prediction value\n",
    "    rawPrediction = min(rawPrediction, 20)\n",
    "    rawPrediction = max(rawPrediction, -20)\n",
    "    return 1 / (1 + exp(-rawPrediction))\n",
    "\n",
    "def evaluateResults(model, data):\n",
    "    \"\"\"Calculates the log loss for the data given the model.\n",
    "\n",
    "    Args:\n",
    "        model (LogisticRegressionModel): A trained logistic regression model.\n",
    "        data (RDD of LabeledPoint): Labels and features for each observation.\n",
    "\n",
    "    Returns:\n",
    "        float: Log loss for the data.\n",
    "    \"\"\"\n",
    "    return data.map(lambda x: computeLogLoss(getP(x.features, model.weights, model.intercept), x.label)).sum() / data.count()\n",
    "\n",
    "def evaluateMetrics(model, data, label):\n",
    "    labelsAndScores = data.map(lambda lp:\n",
    "                            (lp.label, getP(lp.features, model.weights, model.intercept)))\n",
    "    \n",
    "    auc = BinaryClassificationMetrics(labelsAndScores).areaUnderROC\n",
    "    log_loss = evaluateResults(model, data)\n",
    "\n",
    "    sys.stderr.write('\\n LogLoss {0} = {1}'.format(label, log_loss))\n",
    "    sys.stderr.write('\\n AUC {0} = {1}\\n'.format(label, auc))\n",
    "    \n",
    "    return (label, log_loss, auc)\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "    # Initialize the spark context.\n",
    "    sc = SparkContext(appName=\"CriteoBaseline\")\n",
    "\n",
    "    # =========================\n",
    "    # read raw criteo data set\n",
    "    # =========================\n",
    "    rawTrainData = (sc\n",
    "               .textFile(sys.argv[1], 2)\n",
    "               .map(lambda x: x.replace('\\t', ','))\n",
    "               .cache() )# work with either ',' or '\\t' separated data\n",
    "    print rawTrainData.take(1)\n",
    "    \n",
    "    rawTestData = (sc\n",
    "               .textFile(sys.argv[2], 2)\n",
    "               .map(lambda x: x.replace('\\t', ','))\n",
    "               .cache() )# work with either ',' or '\\t' separated data\n",
    "    print rawTestData.take(1)\n",
    "    \n",
    "    rawValidationData = (sc\n",
    "               .textFile(sys.argv[3], 2)\n",
    "               .map(lambda x: x.replace('\\t', ','))\n",
    "               .cache() )# work with either ',' or '\\t' separated data\n",
    "    print rawValidationData.take(1)\n",
    "\n",
    "    # ===================================================\n",
    "    # split into train, validation and test data set\n",
    "    # ===================================================\n",
    "    #weights = [.8, .1, .1]\n",
    "    #seed = 42\n",
    "    # Use randomSplit with weights and seed\n",
    "    #rawTrainData, rawValidationData, rawTestData = rawData.randomSplit(weights, seed)\n",
    "    # Cache the data\n",
    "    #rawTrainData.cache()\n",
    "    #rawValidationData.cache()\n",
    "    #rawTestData.cache()\n",
    "\n",
    "    nTrain = rawTrainData.count()\n",
    "    nVal = rawValidationData.count()\n",
    "    nTest = rawTestData.count()\n",
    "    print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
    "\n",
    "    # ===================================================\n",
    "    # create hash features\n",
    "    # ===================================================\n",
    "    numBucketsCTR = 1000    # number of hash buckets\n",
    "\n",
    "    hashTrainData = rawTrainData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "    hashTrainData.cache()\n",
    "    hashValidationData = rawValidationData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "    hashValidationData.cache()\n",
    "    hashTestData = rawTestData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "    hashTestData.cache()\n",
    "\n",
    "    # ===================================================\n",
    "    # train logistic regression model\n",
    "    # ===================================================    \n",
    "    numIters = 100\n",
    "    stepSize = 10.\n",
    "    regParam = 0. # no regularization\n",
    "    regType = 'l2'\n",
    "    includeIntercept = True\n",
    "\n",
    "    model = LogisticRegressionWithSGD.train(hashTrainData, \n",
    "                                            iterations=numIters, \n",
    "                                            step=stepSize, \n",
    "                                            regParam=regParam, \n",
    "                                            regType=regType, \n",
    "                                            intercept=includeIntercept) \n",
    "    sortedWeights = sorted(model.weights)\n",
    "\n",
    "    sys.stderr.write('\\n Model Intercept: {0}'.format(model.intercept))\n",
    "    sys.stderr.write('\\n Model Weights (Top 5): {0}\\n'.format(sortedWeights[:5]))\n",
    "    \n",
    "    l_metrics = []\n",
    "    \n",
    "    l_metrics.append(evaluateMetrics(model, hashTrainData, 'TRAIN'))\n",
    "    l_metrics.append(evaluateMetrics(model, hashValidationData, 'VALIDATE'))\n",
    "    l_metrics.append(evaluateMetrics(model, hashTestData, 'TEST'))\n",
    "    \n",
    "    sc.parallelize(l_metrics).saveAsTextFile(sys.argv[4])\n",
    "    \n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# copying latest script\n",
    "!scp -i ~/rthallam_sa_east.pem ./criteo_13_4_1.py hadoop@ec2-54-233-134-187.sa-east-1.compute.amazonaws.com:/home/hadoop/src\n",
    "# removing target directory\n",
    "!aws s3 rm s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/ --recursive\n",
    "# launching script\n",
    "!ssh -i ~/rthallam_sa_east.pem hadoop@ec2-54-233-134-187.sa-east-1.compute.amazonaws.com \\\n",
    "    /usr/lib/spark/bin/spark-submit --master yarn-cluster \\\n",
    "    /home/hadoop/src/criteo_13_4_1.py \\\n",
    "    s3://criteo-dataset/rawdata/train/ \\\n",
    "    s3://criteo-dataset/rawdata/test/ \\\n",
    "    s3://criteo-dataset/rawdata/validation/ \\\n",
    "    s3n://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/\n",
    "#!ssh -i ~/rthallam_sa_east.pem hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com /usr/lib/spark/bin/spark-submit --master yarn-cluster /home/hadoop/src/pagerank_13_2.py s3n://ucb-mids-mls-rajeshthallam/hw13/PageRank-test_indexed.txt 10 s3n://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "print \"=\"*80\n",
    "print \"Time taken to find baseline metrics of the Criteo data set = {:.2f} seconds\".format(end_time - start_time)\n",
    "print \"=\"*80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00000 to ./part-00000\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00005 to ./part-00005\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00004 to ./part-00004\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00001 to ./part-00001\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00008 to ./part-00008\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00003 to ./part-00003\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00002 to ./part-00002\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/_SUCCESS to ./_SUCCESS\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00006 to ./part-00006\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00007 to ./part-00007\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00011 to ./part-00011\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00013 to ./part-00013\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00012 to ./part-00012\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00014 to ./part-00014\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00010 to ./part-00010\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00015 to ./part-00015\n",
      "download: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/part-00009 to ./part-00009\n",
      "Results (raw)\n",
      "('TRAIN', 0.5054639969509631, 0.6914759771327955)\n",
      "('VALIDATE', 0.5056761120760903, 0.6918797233560421)\n",
      "('TEST', 0.505602800351624, 0.6920070004287929)\n"
     ]
    }
   ],
   "source": [
    "#Download results\n",
    "!rm -fR .out_hw13_4/part*\n",
    "!aws s3 cp s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_4/ . --recursive\n",
    "    \n",
    "print \"Results (raw)\"\n",
    "!cat part*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:cornflowerblue; font-size:120%\"><b>Results</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:cornflowerblue; font-size:120%\"><b>Results</b></span>\n",
    "\n",
    "<table> \n",
    "<caption>Cluster Configuration and Run Time</caption>\n",
    "<tr><td><b>Cluster Size</b></td><td>3 mx.large (WORKERS) and 1 mx.large (MASTER)</td></tr>\n",
    "<tr><td><b>Run time</b></td><td>2hours 46 minutes</td></tr>\n",
    "</table>\n",
    "\n",
    "![hw_13_4_runtime](hw_13_4_EMR.png)\n",
    "\n",
    "<table> \n",
    "<caption><b>Model parameters</b></caption>\n",
    "<tr>\n",
    "    <th>Parameter</th>\n",
    "    <th>Value</th>\n",
    "</tr>\n",
    "<tr><td>Iterations</td><td>100</td></tr>\n",
    "<tr><td>Regularization</td><td>0.0</td></tr>\n",
    "<tr><td>Regularization Type</td><td>L2</td></tr>\n",
    "<tr><td>Include Intercept</td><td>True</td></tr>\n",
    "<tr><td>Step Size</td><td>10</td></tr>\n",
    "</table>\n",
    "\n",
    "<table> \n",
    "<caption><b>Results: Log loss and AUC</b></caption>\n",
    "<tr>\n",
    "    <th>Data set</th>\n",
    "    <th>Log Loss</th>\n",
    "    <th>AUC</th>\n",
    "</tr>\n",
    "<tr><td>TRAIN</td><td>0.5054639969509631</td><td>0.6914759771327955</td></tr>\n",
    "<tr><td>VALIDATION</td><td>0.5056761120760903</td><td>0.6918797233560421</td></tr>\n",
    "<tr><td>TEST</td><td>0.505602800351624</td><td>0.6920070004287929</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:dodgerblue;font:12px\">HW13.5</span></h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:firebrick; font-size: 120%;\"><b>Criteo Phase 2 Hyperparameter Tuning</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:CornflowerBlue \">Using the training dataset, validation dataset and testing dataset in the Criteo bucket perform the following experiments: <br><br>\n",
    "-- write spark code (borrow from Phase 1 of this project) to train a logistic regression model with various hyperparamters. Do a gridsearch of the hyperparameter space and determine optimal settings using the validation set.<br>\n",
    "-- Number of buckets for hashing: 1,000, 10,000, .... explore different values  here<br>\n",
    "-- Logistic Regression: regularization term: [1e-6, 1e-3]  explore other  values here also<br>\n",
    "-- Logistic Regression: step size: explore different step sizes. Focus on a stepsize of 1 initially.<br><br>\n",
    "Report the AWS cluster configuration that you used and how long in minutes and seconds it takes to complete this job.<br><br>\n",
    "Report in tabular form and using heatmaps the [AUC values](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) for the Training, Validation, and Testing datasets. Report in tabular form and using heatmaps  the logLossTest for the Training, Validation, and Testing datasets.<br><br>\n",
    "Dont forget to put a caption on your tables (above the table) and on your heatmap figures (put caption below figures) detailing the experiment associated with each table or figure (data, algorithm used, parameters and settings explored.<br><br>\n",
    "Discuss the optimal setting to solve this problem in terms of the following:<br>\n",
    "-- Features<br>\n",
    "-- Learning algortihm<br>\n",
    "-- Spark cluster<br><br>\n",
    "Justiy your recommendations based on your experimental results and cross reference with table numbers and figure numbers. Also highlight key results with annotations, both textual and line and box based, on your tables and graphs.\n",
    "</span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:cornflowerblue; font-size: 120%;\"><b>Criteo Phase 2 Hyperparameter Tuning</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting criteo_13_5_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile criteo_13_5_1.py\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "import sys\n",
    "from math import log, exp\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.linalg import SparseVector\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "def hashFunction(numBuckets, rawFeats, printMapping=False):\n",
    "    \"\"\"Calculate a feature dictionary for an observation's features based on hashing.\n",
    "\n",
    "    Note:\n",
    "        Use printMapping=True for debug purposes and to better understand how the hashing works.\n",
    "\n",
    "    Args:\n",
    "        numBuckets (int): Number of buckets to use as features.\n",
    "        rawFeats (list of (int, str)): A list of features for an observation.  Represented as\n",
    "            (featureID, value) tuples.\n",
    "        printMapping (bool, optional): If true, the mappings of featureString to index will be\n",
    "            printed.\n",
    "\n",
    "    Returns:\n",
    "        dict of int to float:  The keys will be integers which represent the buckets that the\n",
    "            features have been hashed to.  The value for a given key will contain the count of the\n",
    "            (featureID, value) tuples that have hashed to that key.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for ind, category in rawFeats:\n",
    "        featureString = category + str(ind)\n",
    "        mapping[featureString] = int(int(hashlib.md5(featureString).hexdigest(), 16) % numBuckets)\n",
    "    if(printMapping): print mapping\n",
    "    sparseFeatures = defaultdict(float)\n",
    "    for bucket in mapping.values():\n",
    "        sparseFeatures[bucket] += 1.0\n",
    "    return dict(sparseFeatures)\n",
    "\n",
    "def parseHashPoint(point, numBuckets):\n",
    "    \"\"\"Create a LabeledPoint for this observation using hashing.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest are\n",
    "            features.\n",
    "        numBuckets: The number of buckets to hash to.\n",
    "\n",
    "    Returns:\n",
    "        LabeledPoint: A LabeledPoint with a label (0.0 or 1.0) and a SparseVector of hashed\n",
    "            features.\n",
    "    \"\"\"\n",
    "    parsedPoints = parsePoint(point)\n",
    "    items = point.split(',')\n",
    "    label = items[0]\n",
    "    features = hashFunction(numBuckets, parsedPoints, printMapping=False)\n",
    "    return LabeledPoint(label, SparseVector(numBuckets, features))\n",
    "\n",
    "def parsePoint(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    return [(i, item) for i, item in enumerate(point.split(',')[1:])]\n",
    "    \n",
    "def computeLogLoss(p, y):\n",
    "    \"\"\"Calculates the value of log loss for a given probabilty and label.\n",
    "\n",
    "    Note:\n",
    "        log(0) is undefined, so when p is 0 we need to add a small value (epsilon) to it\n",
    "        and when p is 1 we need to subtract a small value (epsilon) from it.\n",
    "\n",
    "    Args:\n",
    "        p (float): A probabilty between 0 and 1.\n",
    "        y (int): A label.  Takes on the values 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "        float: The log loss value.\n",
    "    \"\"\"\n",
    "    epsilon = 10e-12\n",
    "    if p == 0:\n",
    "        p = p + epsilon\n",
    "    if p == 1:\n",
    "        p = p - epsilon\n",
    "    return -(y * log(p) + (1-y) * log(1-p))\n",
    "\n",
    "def getP(x, w, intercept):\n",
    "    \"\"\"Calculate the probability for an observation given a set of weights and intercept.\n",
    "\n",
    "    Note:\n",
    "        We'll bound our raw prediction between 20 and -20 for numerical purposes.\n",
    "\n",
    "    Args:\n",
    "        x (SparseVector): A vector with values of 1.0 for features that exist in this\n",
    "            observation and 0.0 otherwise.\n",
    "        w (DenseVector): A vector of weights (betas) for the model.\n",
    "        intercept (float): The model's intercept.\n",
    "\n",
    "    Returns:\n",
    "        float: A probability between 0 and 1.\n",
    "    \"\"\"\n",
    "    rawPrediction = x.dot(w) + intercept\n",
    "\n",
    "    # Bound the raw prediction value\n",
    "    rawPrediction = min(rawPrediction, 20)\n",
    "    rawPrediction = max(rawPrediction, -20)\n",
    "    return 1 / (1 + exp(-rawPrediction))\n",
    "\n",
    "def evaluateResults(model, data):\n",
    "    \"\"\"Calculates the log loss for the data given the model.\n",
    "\n",
    "    Args:\n",
    "        model (LogisticRegressionModel): A trained logistic regression model.\n",
    "        data (RDD of LabeledPoint): Labels and features for each observation.\n",
    "\n",
    "    Returns:\n",
    "        float: Log loss for the data.\n",
    "    \"\"\"\n",
    "    return data.map(lambda x: computeLogLoss(getP(x.features, model.weights, model.intercept), x.label)).sum() / data.count()\n",
    "\n",
    "def evaluateMetrics(model, data, label):\n",
    "    labelsAndScores = data.map(lambda lp:\n",
    "                            (lp.label, getP(lp.features, model.weights, model.intercept)))\n",
    "    \n",
    "    auc = BinaryClassificationMetrics(labelsAndScores).areaUnderROC\n",
    "    log_loss = evaluateResults(model, data)\n",
    "\n",
    "    sys.stderr.write('\\n LogLoss {0} = {1}'.format(label, log_loss))\n",
    "    sys.stderr.write('\\n AUC {0} = {1}\\n'.format(label, auc))\n",
    "    \n",
    "    return (label, log_loss, auc)\n",
    "\n",
    "if __name__ == '__main__':  \n",
    "    # Initialize the spark context.\n",
    "    sc = SparkContext(appName=\"CriteoBaseline\")\n",
    "\n",
    "    # =========================\n",
    "    # read raw criteo data set\n",
    "    # =========================\n",
    "    rawTrainData = (sc\n",
    "               .textFile(sys.argv[1], 2)\n",
    "               .map(lambda x: x.replace('\\t', ','))\n",
    "               .cache() )# work with either ',' or '\\t' separated data\n",
    "    print rawTrainData.take(1)\n",
    "    \n",
    "    rawTestData = (sc\n",
    "               .textFile(sys.argv[2], 2)\n",
    "               .map(lambda x: x.replace('\\t', ','))\n",
    "               .cache() )# work with either ',' or '\\t' separated data\n",
    "    print rawTestData.take(1)\n",
    "    \n",
    "    rawValidationData = (sc\n",
    "               .textFile(sys.argv[3], 2)\n",
    "               .map(lambda x: x.replace('\\t', ','))\n",
    "               .cache() )# work with either ',' or '\\t' separated data\n",
    "    print rawValidationData.take(1)\n",
    "\n",
    "    # ===================================================\n",
    "    # split into train, validation and test data set\n",
    "    # ===================================================\n",
    "    #weights = [.8, .1, .1]\n",
    "    #seed = 42\n",
    "    # Use randomSplit with weights and seed\n",
    "    #rawTrainData, rawValidationData, rawTestData = rawData.randomSplit(weights, seed)\n",
    "    # Cache the data\n",
    "    #rawTrainData.cache()\n",
    "    #rawValidationData.cache()\n",
    "    #rawTestData.cache()\n",
    "\n",
    "    nTrain = rawTrainData.count()\n",
    "    nVal = rawValidationData.count()\n",
    "    nTest = rawTestData.count()\n",
    "    print nTrain, nVal, nTest, nTrain + nVal + nTest\n",
    "\n",
    "    # ===================================================\n",
    "    # create hash features\n",
    "    # ===================================================\n",
    "    numBucketsCTR = [1000, 10000, 10000]    # number of hash buckets\n",
    "    iteration = 0\n",
    "    \n",
    "    for numBuckets in numBucketsCTR:\n",
    "        hashTrainData = rawTrainData.map(lambda x: parseHashPoint(x, numBuckets))\n",
    "        hashTrainData.cache()\n",
    "        hashValidationData = rawValidationData.map(lambda x: parseHashPoint(x, numBuckets))\n",
    "        hashValidationData.cache()\n",
    "        hashTestData = rawTestData.map(lambda x: parseHashPoint(x, numBuckets))\n",
    "        hashTestData.cache()\n",
    "\n",
    "        # ===================================================\n",
    "        # train logistic regression model\n",
    "        # ===================================================    \n",
    "        numIters = 10\n",
    "        stepSizes = [1, 10, 100]\n",
    "        regParams = [1e-6, 1e-3, 1e-1, 0]\n",
    "        regType = 'l2'\n",
    "        includeIntercept = True\n",
    "\n",
    "        for stepSize in stepSizes:\n",
    "            for regParam in regParams:\n",
    "                iteration += 1\n",
    "                l_metrics = []\n",
    "                \n",
    "                l_metrics.append('Buckets=' + str(numBuckets))\n",
    "                l_metrics.append('Step Size=' + str(stepSize))\n",
    "                l_metrics.append('RegParam=' + str(regParam))\n",
    "                \n",
    "                model = LogisticRegressionWithSGD.train(hashTrainData, \n",
    "                                                        iterations=numIters, \n",
    "                                                        step=stepSize, \n",
    "                                                        regParam=regParam, \n",
    "                                                        regType=regType, \n",
    "                                                        intercept=includeIntercept) \n",
    "                sortedWeights = sorted(model.weights)\n",
    "\n",
    "                \n",
    "                sys.stderr.write('\\n Model Intercept: {0}'.format(model.intercept))\n",
    "                sys.stderr.write('\\n Model Weights (Top 5): {0}\\n'.format(sortedWeights[:5]))\n",
    "\n",
    "\n",
    "                l_metrics.append('Intercept=' + str(model.intercept))\n",
    "                l_metrics.append('Weights=' + str(sortedWeights[:5]))\n",
    "                \n",
    "                l_metrics.append(evaluateMetrics(model, hashTrainData, 'TRAIN'))\n",
    "                l_metrics.append(evaluateMetrics(model, hashValidationData, 'VALIDATE'))\n",
    "                l_metrics.append(evaluateMetrics(model, hashTestData, 'TEST'))\n",
    "\n",
    "                sc.parallelize(l_metrics).saveAsTextFile(sys.argv[4] + '/' + str(iteration))\n",
    "    \n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criteo_13_5_1.py                              100% 8985     8.8KB/s   00:00    \n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/_SUCCESS\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00009\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00010\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00000\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00004\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00002\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00005\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00006\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00008\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00001\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00011\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00003\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00013\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00012\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00014\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00015\n",
      "delete: s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/part-00007\n",
      "15/12/09 21:22:33 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# copying latest script\n",
    "!scp -i ~/rthallam_sa_east.pem ./criteo_13_5_1.py hadoop@ec2-54-233-134-187.sa-east-1.compute.amazonaws.com:/home/hadoop/src\n",
    "# removing target directory\n",
    "!aws s3 rm s3://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5/ --recursive\n",
    "# launching script\n",
    "!ssh -i ~/rthallam_sa_east.pem hadoop@ec2-54-233-134-187.sa-east-1.compute.amazonaws.com \\\n",
    "    /usr/lib/spark/bin/spark-submit --master yarn-cluster \\\n",
    "    /home/hadoop/src/criteo_13_5_1.py \\\n",
    "    s3://criteo-dataset/rawdata/train/ \\\n",
    "    s3://criteo-dataset/rawdata/test/ \\\n",
    "    s3://criteo-dataset/rawdata/validation/ \\\n",
    "    s3n://ucb-mids-mls-rajeshthallam/hw13/results/hw13_5\n",
    "#!ssh -i ~/rthallam_sa_east.pem hadoop@ec2-54-233-144-86.sa-east-1.compute.amazonaws.com /usr/lib/spark/bin/spark-submit --master yarn-cluster /home/hadoop/src/pagerank_13_2.py s3n://ucb-mids-mls-rajeshthallam/hw13/PageRank-test_indexed.txt 10 s3n://ucb-mids-mls-rajeshthallam/hw13/results/hw13_2/iter_10/\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "print \"=\"*80\n",
    "print \"Time taken to find find hypertuning parameters for the Criteo data set = {:.2f} seconds\".format(end_time - start_time)\n",
    "print \"=\"*80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:firebrick; font-size: 120%;\"><b>Job is currently running and following scenarios are completed</b><br>Each scenario is running for ~50min on 6 mx.large CORE machines</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO - Pretty print and heatmap**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "::::::::::::::\n",
    "1.txt\n",
    "::::::::::::::\n",
    "Buckets=1000\n",
    "Step Size=1\n",
    "RegParam=1e-06\n",
    "Intercept=0.767382106444\n",
    "Weights=[-0.19950713658592067, -0.19770805634256824, -0.19663784695655784, -0.19489279080272207, -0.15943079452581677]\n",
    "('TRAIN', 0.5434708131061389, 0.6871363591151867)\n",
    "('VALIDATE', 0.5437134818109673, 0.6931797822485392)\n",
    "('TEST', 0.5436171394106204, 0.7084234013945349)\n",
    "::::::::::::::\n",
    "2.txt\n",
    "::::::::::::::\n",
    "Buckets=1000\n",
    "Step Size=1\n",
    "RegParam=0.001\n",
    "Intercept=0.763020956329\n",
    "Weights=[-0.19901607160959192, -0.19722434946331335, -0.19611383648712732, -0.19436933708059378, -0.15896190333515761]\n",
    "('TRAIN', 0.543498592171465, 0.6873449287545953)\n",
    "('VALIDATE', 0.5437409918784116, 0.6923050452782179)\n",
    "('TEST', 0.5436450978729863, 0.710165929684776)\n",
    "::::::::::::::\n",
    "3.txt\n",
    "::::::::::::::\n",
    "Buckets=1000\n",
    "Step Size=1\n",
    "RegParam=0.1\n",
    "Intercept=0.416346799533\n",
    "Weights=[-0.15832838965370033, -0.15704982530780254, -0.15378951908078359, -0.15168715525251408, -0.12153274083272272]\n",
    "('TRAIN', 0.5467704328912172, 0.7403338925210812)\n",
    "('VALIDATE', 0.5469904626994729, 0.6496034652228997)\n",
    "('TEST', 0.5469313836304891, 0.6875515864350759)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:firebrick\">** -- END OF ASSIGNMENT 13 -- **</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
